# RAPID Assessment Questionnaires - Complete Reference

**Version:** 3.0 - Categories organized per original Excel structure  
**Last Updated:** 2025-01-06

---

## ðŸ“Š Statistics

| Section | Questions | Categories |
|---------|-----------|------------|
| Use Case Discovery | 48 | 5 |
| Migration Assessment | 52 | 8 |
| Data Readiness | 25 | 4 |
| Compliance & Integration | 27 | 5 |
| Business Value & ROI | 10 | 1 |

**Total Questions:** 162

---

# Use Case 1: New GenAI Development (Exploratory)

## Step 1: Use Case Discovery

### Business Context and Use Case Definition

**Q1.1** What business problem(s) does your GenAI application aim to solve? Can you describe the user and use case in terms of your business or operational needs?

*Establishes the fundamental business purpose and identifies key user personas for the application.*

**Q1.2** What is the current state of this use case (in progress, ideated, etc.)?

*Determines where in the planning/development lifecycle the use case currently stands.*

**Q1.3** What is the urgency for this use case? Is there an impending event or target date to launch?

*Identifies timeline constraints and helps prioritize implementation activities.*

**Q1.4** Who is the business owner for this use case (name, title, and/or group)?

*Establishes primary stakeholder and decision-maker for the project.*

**Q1.5** What is the primary goal or success criteria of the use case?

*Clarifies measurable outcomes that will define success for the implementation.*

**Q1.6** How does this use case align with your organization's strategic goals?

*Connects the GenAI initiative to broader organizational priorities and value creation.*

**Q1.7** What specific pain points does this GenAI application aim to address?

*Identifies current problems the application will solve, establishing baseline for ROI calculations.*

**Q1.8** Are there existing workflows or processes that will be replaced or enhanced?

*Maps the implementation to current operational activities for smoother transition planning.*

**Q1.9** What is the expected business impact in the first 3/6/12 months?

*Establishes timeline for expected value realization and helps set realistic expectations.*

**Q1.10** Are there any immediate cost savings or revenue generation opportunities?

*Identifies quick financial wins that could help justify the investment and build momentum.*

**Q1.11** How will you measure ROI for this implementation?

*Establishes key metrics for business value assessment.*

**Q1.12** What is the scope of impact in terms of users or departments affected?

*Helps quantify the reach and potential scale of the solution's impact across the organization*

---

### Evaluation and Success Metrics

**Q1.1** How will you measure the success of this GenAI implementation?

*Establishes key performance indicators for value assessment.*

**Q1.2** What quantitative metrics are important (time saved, error reduction, etc.)?

*Identifies specific measurable outcomes for ROI calculation.*

**Q1.3** What qualitative feedback will you gather from users?

*Establishes user satisfaction measurement approach.*

**Q1.4** How will you determine if the AI outputs meet quality expectations?

*Identifies quality control mechanisms and standards.*

**Q1.5** What are your primary concerns about implementing this GenAI application?

*Identifies perceived risks and concerns for proactive addressing.*

**Q1.6** What baseline metrics exist for current processes being replaced?

*Provides comparison data for improvement measurement.*

**Q1.7** Who will be responsible for ongoing evaluation of the application?

*Identifies ownership of performance monitoring and optimization.*

**Q1.8** What constitutes a minimum viable product for initial deployment?

*Establishes scope requirements for initial release.*

**Q1.9** How important is factuality and citation in model outputs?

*Establishes accuracy requirements and hallucination tolerance.*

**Q1.10** â€¢ Set accuracy/performance targets
â€¢ Define latency requirements
â€¢ Establish cost parameters
â€¢ Document additional requirements

*Define clear success criteria (accuracy, latency, cost)*

---

### Implementation Considerations

**Q1.1** What is your preferred development timeline?

*Establishes scheduling expectations and milestone planning.*

**Q1.2** Do you have in-house AI/ML expertise?

*Determines level of guidance and support needed during implementation.*

**Q1.3** Who are the primary end users of the application?

*Identifies the specific user groups who will directly interact with the application.*

**Q1.4** How tech-savvy are your intended users?

*Helps gauge appropriate user interface complexity and training requirements.*

**Q1.5** How will users interact with the GenAI application?

*Determines interface design and interaction model requirements.*

**Q1.6** Do you prefer cloud-based, on-premises, or hybrid deployment?

*Determines infrastructure approach and hosting requirements.*

**Q1.7** Are there any existing AI governance policies that must be followed?

*Identifies organizational constraints on AI deployment.*

**Q1.8** Will users need to save, export, or share AI outputs?

*Identifies additional functionality beyond core AI capabilities.*

**Q1.9** What is your budget range for this implementation?

*Helps scope appropriate solution within financial constraints.*

**Q1.10** What resources can your organization commit to this project?

*Identifies available internal support for implementation.*

**Q1.11** Would you prefer a phased approach with iterative deployments?

*Determines release strategy and milestone planning.*

---

### Technical Requirements and Constraints

**Q1.1** What types of data sources are required to support your generative AI workloads?

*Maps data ecosystem needed to support the application.*

**Q1.2** What is the expected volume of data or requests for the use case?

*Establishes scale requirements for infrastructure planning.*

**Q1.3** Are there any existing systems this GenAI application needs to integrate with?

*Identifies integration points and potential technical constraints.*

**Q1.4** What types of AI capabilities are most important for your use case (text generation, classification, summarization, etc.)?

*Identifies core AI functions needed for the implementation.*

**Q1.5** Are there any specific regulatory or compliance requirements that must be addressed?

*Identifies legal and governance constraints for the implementation.*

**Q1.6** Will your application require domain-specific knowledge or expertise?

*Determines need for domain-specific training or fine-tuning.*

**Q1.7** Do you require multimodal capabilities (text, images, audio)?

*Identifies additional model requirements beyond text processing.*

**Q1.8** Do you have specific latency or response time requirements?

*Establishes performance expectations and SLA requirements.*

**Q1.9** How frequently do you need to update or refresh data from these sources?

*Determines real-time vs. batch processing requirements and data currency needs.*

**Q1.10** What data formats do your generative AI models require as input?

*Identifies data transformation and preparation requirements.*

**Q1.11** What is your expected peak throughput in terms of requests per minute/hour?

*Helps size infrastructure and determine scaling requirements.*

**Q1.12** Do you have preferences for specific LLM platforms or models?

*Determines model selection constraints or preferences.*

**Q1.13** What platforms will users use to access this application (web, mobile, API, etc.)?

*Determines UI/UX requirements and delivery channels.*

---

### Use-case Prioritization

**Q1.1** How do you approach prioritizing and sequencing generative AI workload assessments across different projects and departments in your organization?

*Use-case priorization framework used [For example: 

Business Value Impact (40%)
-----------------------------------------
Strategic Alignment (0-10)
Financial Impact (0-10)
Operational Efficiency (0-10)
Urgency/Time Sensitivity (0-10)

Technical Feasibility (30%)
-----------------------------------------
Data Readiness (0-10)
Technical Complexity (0-10)
Integration Requirements (0-10)
Compliance/Security Fit (0-10)

Implementation Readiness (30%)
-----------------------------------------
Resource Availability (0-10)
Budget Alignment (0-10)
Timeline Feasibility (0-10)
Organizational Support (0-10)

Scoring calculation
Final Score = (Business Value Ã— 0.4) + (Technical Feasibility Ã— 0.3) + (Implementation Readiness Ã— 0.3)]*

**Q1.2** What are the key stakeholders need to be involved in this process?

*Identifies additional participants whose input will be crucial for success.*

---

## Step 2: Data Readiness Assessment

### AI-Specific Data Preparation

**Q2.1** Do you have labeled datasets available for training or fine-tuning models?

*Assesses availability of supervised learning data if model customization is required.*

**Q2.2** Have you performed any data profiling or exploratory analysis on your datasets?

*Determines understanding of data characteristics that might impact AI performance.*

**Q2.3** Are there known biases or gaps in your data that could affect AI outputs?

*Identifies potential ethical concerns and performance limitations to address.*

**Q2.4** Have you established ground truth or benchmark datasets for evaluating AI performance?

*Assesses readiness for measuring AI output quality and accuracy.*

**Q2.5** Do you have mechanisms to monitor data drift or quality changes over time?

*Identifies capabilities for maintaining AI performance as data evolves.*

**Q2.6** Do you have processes in place to handle missing, incomplete, or inconsistent data?

*Evaluates maturity of data cleansing procedures critical for reliable AI outputs.*

**Q2.7** What percentage of your data meets your quality standards for generative AI use?

*Quantifies the proportion of data that is immediately usable versus requiring cleanup*

---

### Data Format & Preprocessing

**Q2.1** What data formats comprise your relevant data (structured, unstructured, semi-structured)?

*Determines compatibility with GenAI processing requirements and necessary transformations.*

**Q2.2** Are your data sources centralized or distributed across multiple systems?

*Identifies potential data integration challenges and accessibility issues.*

**Q2.3** What data pipeline infrastructure do you currently have in place?

*Evaluates existing ETL/ELT capabilities that can support GenAI data flow.*

**Q2.4** Can your current infrastructure support real-time data processing if required?

*Determines if infrastructure upgrades are needed for latency-sensitive applications.*

**Q2.5** What languages are represented in your data?

*Identifies multilingual requirements and potential challenges.*

**Q2.6** What text preprocessing or normalization steps have you applied to your data?

*Evaluates text-specific preparation work completed for NLP applications.*

---

### Data Quality & Governance

**Q2.1** How do you ensure and measure the quality of your data?

*Assesses existing data quality processes and metrics that would impact GenAI performance.*

**Q2.2** How do you classify and manage sensitive information within your datasets?

*Assesses risk management practices for personally identifiable or confidential information.*

**Q2.3** Do you have documented data lineage for the sources you plan to use?

*Determines traceability and auditability of data feeding into the GenAI system.*

**Q2.4** What data access controls and permissions are currently in place?

*Identifies security measures and potential constraints for AI system access to data.*

**Q2.5** Who owns and manages the data sources you plan to use?

*Identifies data stewards and access approval processes.*

**Q2.6** How do you plan to build trust about data usage in generative AI among stakeholders?

*Evaluates transparency and communication strategies regarding AI data usage.*

---

### Data Volume & Storage Requirements

**Q2.1** What is the current volume of relevant data available for your GenAI application?

*Quantifies data scale to determine processing and storage requirements.*

**Q2.2** Where will the training data be stored?

*Maps current and planned data repositories and access methods.*

**Q2.3** What are the storage requirements for training data and model artifacts?

*Determines capacity, durability, and availability requirements.*

**Q2.4** What are the data retention and backup requirements?

*Determines storage lifecycle management requirements.*

**Q2.5** How frequently is your data updated or refreshed?

*Assesses data currency requirements and pipeline update frequencies.*

**Q2.6** How do you handle versioning and storage of different iterations of training datasets?

*Evaluates version control practices and their impact on storage needs.*

---

## Step 3: Compliance & Integration

### Enterprise Integration

**Q3.1** What existing systems will the GenAI application need to integrate with?

*Maps integration points that will require API development or connectors.*

**Q3.2** Do you have existing single sign-on (SSO) or identity management systems to leverage?

*Identifies authentication integration requirements for seamless user experience.*

**Q3.3** What APIs or service endpoints are available for integration with your current systems?

*Evaluates available technical connection points for enterprise integration.*

**Q3.4** Are there specific data exchange formats required for compatibility with your systems?

*Identifies format requirements for input/output compatibility.*

**Q3.5** What latency or performance requirements exist for integrations?

*Establishes performance expectations for integrated operations.*

---

### Governance & Risk Management

**Q3.1** Who are the key stakeholders responsible for AI governance and compliance?

*Identifies key stakeholders and decision-makers for compliance matters.*

**Q3.2** What monitoring and reporting processes are needed for AI system oversight?

*Determines operational governance requirements for ongoing supervision.*

**Q3.3** What are your thresholds and criteria for human review of AI outputs?

*Identifies when human intervention is required in AI processes.*

**Q3.4** What change management processes apply to AI model updates or system changes?

*Evaluates controls for managing system evolution while maintaining compliance.*

**Q3.5** How will you monitor for and address model drift or performance degradation?

*Identifies ongoing quality management approaches for long-term stability.*

**Q3.6** What is your organization's approach to managing bias in AI systems?

*Assesses awareness and mitigation strategies for AI fairness issues.*

**Q3.7** Have you conducted a risk assessment specific to this GenAI implementation?

*Determines if formal risk evaluation has been performed for the use case.*

---

### Legal and Licensing

**Q3.1** Have you reviewed licensing terms for all models and data sources you plan to use?

*Ensures awareness of legal usage constraints for third-party components.*

**Q3.2** What intellectual property considerations apply to AI-generated content?

*Clarifies ownership and rights related to system outputs.*

**Q3.3** Have you established terms of service or user agreements for your GenAI application?

*Determines if legal frameworks for user interaction are in place.*

**Q3.4** What are your requirements for AI explainability and transparency?

*Determines  AI explainability and transparency requirements*

---

### Regulatory Compliance

**Q3.1** What industry-specific regulations apply to your AI implementation (HIPAA, GDPR, CCPA, etc.)?

*Identifies specific regulatory frameworks that will govern AI usage in the customer's context.*

**Q3.2** Have you conducted a privacy impact assessment for this GenAI use case?

*Determines if formal privacy evaluation has been completed to identify potential risks.*

**Q3.3** What requirements do you have for explainability and transparency of AI decisions?

*Assesses need for interpretable AI and documentation of decision processes.*

**Q3.4** What data sovereignty requirements must be addressed?

*Determines geographic constraints on data processing and storage.*

**Q3.5** Do you have protocols for handling right-to-be-forgotten or data deletion requests?

*Evaluates readiness for managing consumer privacy rights that may affect model training data.*

**Q3.6** What audit trails or logging requirements apply to your AI system?

*Identifies logging and traceability requirements..*

---

### Security Considerations

**Q3.1** Have you established data classification levels for information processed by the AI system?

*Assesses maturity of data security categorization that will affect access controls.*

**Q3.2** What authentication and authorization mechanisms are required for your GenAI application?

*Identifies security controls needed for user access management.*

**Q3.3** Do you have requirements for encryption of data at rest and in transit?

*Determines security protocols needed for data protection throughout the AI pipeline.*

**Q3.4** Have you conducted a threat modeling exercise for the proposed GenAI application?

*Assesses proactive security planning and risk identification.*

**Q3.5** What content moderation or filtering requirements exist?

*Identifies safety mechanisms needed for user-facing content.*

---

## Step 4: Model Evaluation

### 4.1 Evaluation Process Guidelines

#### Prepare Data Samples

**Select Evaluation Basis**

Select between ground truth samples or deterministic metrics for evaluation.

**Prepare Data**

Clean and format samples properly while ensuring they represent actual use cases.

**Include Test Scenarios**

Incorporate both common scenarios and edge cases for thorough testing.

**Maintain Standards**

Use consistent structure, provide relevant context, and follow standardized formatting.

**Assess Quality**

Verify data cleanliness, context length, documentation, input variety, and error conditions.

#### Select Evaluation Frameworks and Metrics

**Define Evaluation Metrics**

Select appropriate evaluation metrics for GenAI use cases, combining both human SME evaluation and automated metrics for better scalability and objectivity. Options include:
â€¢ Human evaluation by Subject Matter Experts (SME)
â€¢ Automated evaluation metrics

**Define the clear Success Criteria**

After obtaining alignment on the evaluation methods and metrics with stakeholders, please work with them to define clear success criteria.

#### Model Selection

**Model Selection**

Select LLM / FM that meets key evaluating criteria, such as:
â€¢ Input and output modalities (text, code, multi-modal capabilities)
â€¢ Context window size: Maximum input tokens the model can process
â€¢ Cost per inference or token
â€¢ Performance metrics (latency, throughput)
â€¢ Output quality and accuracy
â€¢ Domain specialization and specific use case compatibility
â€¢ Hosting options (cloud, on-premise, hybrid)
â€¢ Data privacy and security requirements

#### Evaluation and Optimization

**Test model response**

Run the model

**Capture evaluation results**

Capture automated and Human evaluation results

**Prompt Optimization**

Optimize prompt to enhance performance through refined inputs and automated tools, such as, Bedrock Automatic Prompt Optimization (APO) and Metaprompt tool offered by Anthropic.

**Latency Optimization**

Reduce the latency by optimizing prompt to generate shorter answers (reduce the number of output tokens) and when needed use Provisioned Throughput

**Refine LLM responses**

Evaluation of generated response is an iterative process. Test and redefine/optimize prompts, models, and configurations with controlled variables.

**Cost calculation**

For LLM invocation, the cost can be calculated based on the number of input and output tokens and the corresponding price per token:

LLM_invocation_cost = number_of_input_tokens * price_per_input_token + number_of_output_tokens * price_per_output_token

**Document model performance comparison**

Prepare model performance (accuracy, latency, cost, & more) for all the tested models.

### 4.2 Evaluation Metrics

#### Latency

- **Latency:** Response time for model inference
- **Throughput:** Number of requests processed per unit time
- **TTFT:** Time To First Token - Time until first response token
- **Other:** Other latency-related metrics

#### Quality

- **Correctness:** Accuracy of model responses
- **Completeness:** Whether responses fully address the query
- **Faithfulness:** Adherence to source information without hallucination
- **Helpfulness:** Usefulness of responses to users
- **Logical coherence:** Consistency and logic in responses
- **Relevance:** How relevant responses are to the query
- **Following instructions:** Ability to follow specific instructions
- **Professional style and tone:** Appropriateness of language style
- **Harmfulness:** Potential for harmful or unsafe outputs
- **Stereotyping:** Presence of biased or stereotypical content
- **Refusal:** Appropriate refusal of inappropriate requests
- **Other:** Other quality metrics

#### Cost

- **Cost per request:** Cost calculation based on input/output tokens

---

## Step 5: Business Value & ROI

### Business Value and ROI

**Q5.1** What success metrics are tracked for your GenAI application?

*Identifies how business value is measured.*

**Q5.2** What is the estimated business impact in terms of:
* Cost savings
* Revenue generation
* Productivity improvement
* Customer experience enhancement?

*Identifies unanticipated outcomes from deployment. Quantifies operational improvements from implementation.*

**Q5.3** How many users/departments would benefit from this solution?

*Assesses qualitative improvements and user experience.*

**Q5.4** What is the urgency for implementing this use case? Are there any critical deadlines?

*Identifies timeline constraints and helps prioritize implementation activities.*

**Q5.5** How do executives or stakeholders perceive the value of the application?

*Assesses leadership support and perception.*

**Q5.6** What is the current manual effort or cost associated with this process?

*Assesses effort estiamtion and cost*

**Q5.7** Are there existing solutions in place? Why are they inadequate?

*Maps the implementation to current operational activities for smoother transition planning.*

**Q5.8** What specific pain points or business challenges does this GenAI use case aim to address?

*Identifies current problems the application will solve, establishing baseline for ROI calculations.*

**Q5.9** What is your estimated ROI for this application?

*Quantifies overall business value delivered.*

**Q5.10** What is the expected business impact in the first 3/6/12 months?

*Establishes timeline for expected value realization.*

---

# Use Case 2: GenAI Migration to AWS

## Step 1: Use Case Discovery

*Same as Exploratory Step 1*

---

## Step 2: Current System Assessment (Migration Only)

### Agent and Function Implementations

**Q2.1** Does your application use agent architectures?

*Identifies if autonomous agents are employed in the solution.*

**Q2.2** What agent frameworks or architectures do you employ?

*Details specific agent implementation approaches.*

**Q2.3** What orchestration tools or frameworks do you use?

*Identifies workflow and process management components to be migrated or replaced.*

**Q2.4** How do you manage function calling and API access?

*Addresses security and orchestration of external tool access.*

---

### LLM and Model Information

**Q2.1** Which large language model(s) are you currently using?

*Identifies specific model selection (e.g., GPT-4, Claude 3, Llama 3, etc.).*

**Q2.2** Are you using first-party APIs or self-hosted models?

*Distinguishes between cloud API-based and on-premises deployments.*

**Q2.3** If using self-hosted models, what infrastructure are they deployed on?

*Identifies hardware requirements and on-premises setup.*

**Q2.4** What model parameters/sizes are you utilizing?

*Assesses the computational requirements and capabilities of models in use.*

**Q2.5** Do you fine-tune or customize your models? If so, how?

*Evaluates model customization approaches and sophistication.*

**Q2.6** What was your model selection process?

*Provides insight into decision criteria for model selection.*

**Q2.7** What are your current model inference costs?

*Quantifies financial considerations for model usage.*

---

### Model Outputs and Samples

**Q2.1** Can you provide sample inputs and outputs from your system?

*Requests concrete examples for quality assessment.*

**Q2.2** What are examples of high-quality vs. low-quality responses?

*Establishes quality benchmarks and expectations.*

**Q2.3** How consistent are model responses across similar queries?

*Evaluates consistency and reliability.*

**Q2.4** What types of queries or tasks perform best with your implementation?

*Identifies strengths and optimal use cases.*

**Q2.5** What types of queries or tasks perform poorly?

*Identifies limitations and areas for improvement.*

**Q2.6** Can you share any user feedback on model outputs?

*Provides external perspectives on quality and value.*

**Q2.7** Can you provide a high-level diagram of your GenAI platform architecture?

*Requests visual representation of the overall system to guide migration planning.*

---

### Performance and SLAs

**Q2.1** What are your defined SLAs for the application?

*Identifies formal performance commitments.*

**Q2.2** What KPIs do you track for your GenAI platform?

*Lists metrics used to measure success.*

**Q2.3** How do you measure model performance and quality?

*Evaluates approaches to assessing model outputs.*

**Q2.4** What are your current biggest performance bottlenecks?

*Identifies areas for improvement.*

**Q2.5** How do you handle rate limiting and capacity management?

*Evaluates load management strategies.*

**Q2.6** What caching strategies are implemented?

*Identifies performance optimization techniques.*

**Q2.7** How do you scale your application during peak demand?

*Assesses elasticity and scaling capabilities.*

---

### Prompt Engineering and Management

**Q2.1** How do you structure your prompts?

*Assesses prompt engineering sophistication.*

**Q2.2** Do you use templates, few-shot learning, or other prompt techniques?

*Identifies specific prompt engineering strategies.*

**Q2.3** How do you manage prompt versioning and updates?

*Evaluates prompt management processes and governance.*

**Q2.4** Do you have a prompt library or centralized management system?

*Identifies prompt reuse and standardization practices.*

**Q2.5** How do you optimize prompts for performance and accuracy?

*Evaluates prompt refinement processes.*

**Q2.6** Can you share examples of your most effective prompts?

*Provides concrete examples for analysis.*

---

### RAG (Retrieval-Augmented Generation) Implementation

**Q2.1** Do you use RAG techniques in your application?

*Determines if retrieval is used to enhance generation.*

**Q2.2** What data sources are integrated into your RAG system?

*Identifies content types and sources used for retrieval.*

**Q2.3** Which vector database or embedding store do you use?

*Identifies technical implementation of vector storage.*

**Q2.4** What embedding models do you use?

*Details specific embedding approaches and models.*

**Q2.5** How do you structure and chunk your documents for embedding?

*Evaluates document processing approaches.*

**Q2.6** What is your retrieval strategy (semantic search, hybrid search, reranking)?

*Details implementation of search and retrieval components.*

**Q2.7** How do you measure retrieval quality and relevance?

*Identifies evaluation metrics for retrieval effectiveness.*

**Q2.8** How frequently is your knowledge base updated?

*Assesses freshness and maintenance of retrieved information.*

---

### Security and Governance

**Q2.1** How do you authenticate and authorize users?

*Assesses access control mechanisms.*

**Q2.2** How do you secure API endpoints and model access?

*Evaluates API security practices.*

**Q2.3** What PII (Personally Identifiable Information) handling procedures are in place?

*Assesses data privacy compliance.*

**Q2.4** Do you implement content filtering or moderation? How?

*Evaluates safety measures for generated content.*

**Q2.5** What logging and audit mechanisms are in place?

*Assesses compliance and security monitoring.*

**Q2.6** How do you handle data sovereignty and regional compliance requirements?

*Evaluates geographic and regulatory compliance.*

**Q2.7** What incident response procedures exist for AI-related failures?

*Assesses preparedness for AI-specific incidents.*

---

### Usage Metrics

**Q2.1** What is the total number of active users on your platform?

*Establishes the scale of user adoption.*

**Q2.2** What is your average and peak concurrent user count?

*Helps understand typical and maximum load on the application.*

**Q2.3** What is your average daily/monthly query volume?

*Quantifies overall application usage.*

**Q2.4** When do you experience peak usage hours?

*Identifies time-based usage patterns that may affect performance requirements.*

**Q2.5** What is your average response time during normal operations and peak hours?

*Establishes typical performance metrics and identifies performance degradation during high load scenarios*

**Q2.6** How has usage grown over the past 6 months?

*Tracks adoption trends and growth trajectory.*

---

## Steps 3-6

*Same as Exploratory Steps 2-5 with migration focus*

